{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "556c9341-b682-40e4-8973-e87f22f10955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get the accessKey and secretKey from Environment\n",
    "accessKey = os.environ['AWS_ACCESS_KEY_ID']\n",
    "secretKey = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "# point to mesos master or zookeeper entry (e.g., zk://10.10.10.10:2181/mesos)\n",
    "conf.setMaster(\"spark://spark-master:7077\")\n",
    "\n",
    "# set other options as desired\n",
    "conf.set(\"spark.executor.memory\", \"8g\")\n",
    "conf.set(\"spark.executor.cores\", \"1\")\n",
    "conf.set(\"spark.core.connection.ack.wait.timeout\", \"1200\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio-1:9000\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.path.style.access\", \"true\")\n",
    "conf.set(\"spark.hadoop.fs.s3a.access.key\", accessKey)\n",
    "conf.set(\"spark.hadoop.fs.s3a.secret.key\", secretKey)\n",
    "conf.set(\"spark.hadoop.fs.s3a.aws.credentials.provider\", \"org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\")\n",
    "conf.set(\"spark.sql.catalogImplementation\", \"hive\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "conf.set(\"spark.sql.catalog.hive\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hive\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.uri\", \"thrift://hive-metastore:9083\")\n",
    "conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", \"s3a://admin-bucket/iceberg/warehouse\")\n",
    "conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.10.0\")\n",
    "conf.set(\"spark.sql.legacy.allowNonEmptyLocationInCTAS\",\"true\")\n",
    "conf.set(\"spark.sql.hive.metastore.jars\",\"builtin\")\n",
    "\n",
    "spark = SparkSession.builder.appName('Jupyter').config(conf=conf).getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"INFO\")\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96854923-caf9-4f1e-bedd-a23fff179726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_set(batch_curr, batch_chg, load_date):\n",
    "    batch_dict = {row[0]: row for row in batch_curr}\n",
    "    \n",
    "    #  Step 2: Update/add rows from batch_upd\n",
    "    for row in batch_chg:\n",
    "        person_id = row[0]\n",
    "        action = row[1]\n",
    "        if action == \"DEL\":\n",
    "            # Delete the record if it exists\n",
    "            batch_dict.pop(person_id, None)\n",
    "        else:\n",
    "            # Otherwise, update/add\n",
    "            batch_dict[person_id] = row + (load_date,)\n",
    "    \n",
    "    # Step 3: Convert back to list and replace load_date in each row\n",
    "    merged_batch = [row[:-1] + (load_date,) for row in batch_dict.values()]\n",
    "    \n",
    "    # Optional: sort by person_id\n",
    "    merged_batch.sort(key=lambda x: x[0])\n",
    "\n",
    "    return merged_batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036bb971-d4c3-4f6f-9cc2-67ab88296c0a",
   "metadata": {},
   "source": [
    "#### Batch 1 – Initial load (T1)\n",
    " * All records are new inserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d8c974-22be-4923-9f95-710a13dc5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = [\n",
    "    (1,  \"Alice\",  \"Meyer\",   \"Zurich\",  \"alice.meyer@example.com\", \"ACTIVE\"),\n",
    "    (2,  \"Bob\",    \"Keller\",  \"Bern\",    \"bob.keller@example.com\", \"ACTIVE\"),\n",
    "    (3,  \"Clara\",  \"Schmid\",  \"Basel\",   \"clara.schmid@example.com\", \"ACTIVE\"),\n",
    "    (4,  \"David\",  \"Fuchs\",   \"Zurich\",  \"david.fuchs@example.com\", \"ACTIVE\"),\n",
    "    (5,  \"Eva\",    \"Brunner\", \"Lucerne\", \"eva.brunner@example.com\", \"ACTIVE\"),\n",
    "    (6,  \"Frank\",  \"Weber\",   \"Bern\",    \"frank.weber@example.com\", \"ACTIVE\"),\n",
    "    (7,  \"Grace\",  \"Huber\",   \"Basel\",   \"grace.huber@example.com\", \"ACTIVE\"),\n",
    "    (8,  \"Henry\",  \"Meier\",   \"Zurich\",  \"henry.meier@example.com\", \"ACTIVE\"),\n",
    "    (9,  \"Irene\",  \"Kunz\",    \"Bern\",    \"irene.kunz@example.com\", \"ACTIVE\"),\n",
    "    (10, \"Jonas\",  \"Baum\",    \"StGallen\",\"jonas.baum@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_1_load_date = \"2024-01-01\"\n",
    "batch_1 = create_full_set([], batch_1, batch_1_load_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99a4749a-ad9f-4c30-bd4b-6d594ed6b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 'Meyer', 'Zurich', 'alice.meyer@example.com', 'ACTIVE', '2024-01-01'), (2, 'Bob', 'Keller', 'Bern', 'bob.keller@example.com', 'ACTIVE', '2024-01-01'), (3, 'Clara', 'Schmid', 'Basel', 'clara.schmid@example.com', 'ACTIVE', '2024-01-01'), (4, 'David', 'Fuchs', 'Zurich', 'david.fuchs@example.com', 'ACTIVE', '2024-01-01'), (5, 'Eva', 'Brunner', 'Lucerne', 'eva.brunner@example.com', 'ACTIVE', '2024-01-01'), (6, 'Frank', 'Weber', 'Bern', 'frank.weber@example.com', 'ACTIVE', '2024-01-01'), (7, 'Grace', 'Huber', 'Basel', 'grace.huber@example.com', 'ACTIVE', '2024-01-01'), (8, 'Henry', 'Meier', 'Zurich', 'henry.meier@example.com', 'ACTIVE', '2024-01-01'), (9, 'Irene', 'Kunz', 'Bern', 'irene.kunz@example.com', 'ACTIVE', '2024-01-01'), (10, 'Jonas', 'Baum', 'StGallen', 'jonas.baum@example.com', 'ACTIVE', '2024-01-01')]\n"
     ]
    }
   ],
   "source": [
    "print(batch_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c22e0a0-832a-4267-be24-d3cb380936e1",
   "metadata": {},
   "source": [
    "#### Batch 2 – First changes (2024-01-05)\n",
    " * Alice moves to Bern\n",
    " * Clara changes email\n",
    " * Frank moves to Zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c812770-e97e-44e6-8d6f-aed16a3499d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 'Meyer', 'Bern', 'alice.meyer@example.com', 'ACTIVE', '2024-01-05'), (2, 'Bob', 'Keller', 'Bern', 'bob.keller@example.com', 'ACTIVE', '2024-01-05'), (3, 'Clara', 'Schmid', 'Basel', 'clara.schmid@newmail.com', 'ACTIVE', '2024-01-05'), (4, 'David', 'Fuchs', 'Zurich', 'david.fuchs@example.com', 'ACTIVE', '2024-01-05'), (5, 'Eva', 'Brunner', 'Lucerne', 'eva.brunner@example.com', 'ACTIVE', '2024-01-05'), (6, 'Frank', 'Weber', 'Zurich', 'frank.weber@example.com', 'ACTIVE', '2024-01-05'), (7, 'Grace', 'Huber', 'Basel', 'grace.huber@example.com', 'ACTIVE', '2024-01-05'), (8, 'Henry', 'Meier', 'Zurich', 'henry.meier@example.com', 'ACTIVE', '2024-01-05'), (9, 'Irene', 'Kunz', 'Bern', 'irene.kunz@example.com', 'ACTIVE', '2024-01-05'), (10, 'Jonas', 'Baum', 'StGallen', 'jonas.baum@example.com', 'ACTIVE', '2024-01-05')]\n"
     ]
    }
   ],
   "source": [
    "batch_2_chg = [\n",
    "    (1,  \"Alice\",  \"Meyer\",   \"Bern\",  \"alice.meyer@example.com\", \"ACTIVE\"),\n",
    "    (3, \"Clara\", \"Schmid\", \"Basel\",  \"clara.schmid@newmail.com\", \"ACTIVE\"),\n",
    "    (6, \"Frank\", \"Weber\",  \"Zurich\", \"frank.weber@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_2_load_date = \"2024-01-05\"\n",
    "batch_2 = create_full_set(batch_1, batch_2_chg, batch_2_load_date)\n",
    "print(batch_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438841e5-6655-4292-9287-d883d4453232",
   "metadata": {},
   "source": [
    "#### Batch 3 – New joiners + no-op (2024-01-10)\n",
    " * Eva is unchanged\n",
    " * Kevin and Luara are new joiners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e49e752c-dd75-4240-b6df-896536dd56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 'Meyer', 'Bern', 'alice.meyer@example.com', 'ACTIVE', '2024-01-10'), (2, 'Bob', 'Keller', 'Bern', 'bob.keller@example.com', 'ACTIVE', '2024-01-10'), (3, 'Clara', 'Schmid', 'Basel', 'clara.schmid@newmail.com', 'ACTIVE', '2024-01-10'), (4, 'David', 'Fuchs', 'Zurich', 'david.fuchs@example.com', 'ACTIVE', '2024-01-10'), (5, 'Eva', 'Brunner', 'Lucerne', 'eva.brunner@example.com', 'ACTIVE', '2024-01-10'), (6, 'Frank', 'Weber', 'Zurich', 'frank.weber@example.com', 'ACTIVE', '2024-01-10'), (7, 'Grace', 'Huber', 'Basel', 'grace.huber@example.com', 'ACTIVE', '2024-01-10'), (8, 'Henry', 'Meier', 'Zurich', 'henry.meier@example.com', 'ACTIVE', '2024-01-10'), (9, 'Irene', 'Kunz', 'Bern', 'irene.kunz@example.com', 'ACTIVE', '2024-01-10'), (10, 'Jonas', 'Baum', 'StGallen', 'jonas.baum@example.com', 'ACTIVE', '2024-01-10'), (11, 'Kevin', 'Loosli', 'Bern', 'kevin.loosli@example.com', 'ACTIVE', '2024-01-10'), (12, 'Laura', 'Graf', 'Basel', 'laura.graf@example.com', 'ACTIVE', '2024-01-10')]\n"
     ]
    }
   ],
   "source": [
    "batch_3_chg = [\n",
    "    (5,  \"Eva\",   \"Brunner\", \"Lucerne\",\"eva.brunner@example.com\", \"ACTIVE\"),\n",
    "    (11, \"Kevin\", \"Loosli\",  \"Bern\",  \"kevin.loosli@example.com\", \"ACTIVE\"),\n",
    "    (12, \"Laura\", \"Graf\",    \"Basel\", \"laura.graf@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_3_load_date = \"2024-01-10\"\n",
    "batch_3 = create_full_set(batch_2, batch_3_chg, batch_3_load_date)\n",
    "print (batch_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5915c9-b1d0-4041-a5a1-199e16a95643",
   "metadata": {},
   "source": [
    "#### Batch 4 – Multi-field changes (2024-01-15)\n",
    " * Bob changes city + email\n",
    " * Grace moves to Bern \n",
    " * Henry changes email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3540cabe-cbe6-47c2-8556-00622f07b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 'Meyer', 'Bern', 'alice.meyer@example.com', 'ACTIVE', '2024-01-15'), (2, 'Bob', 'Keller', 'Zurich', 'bob.keller@corp.com', 'ACTIVE', '2024-01-15'), (3, 'Clara', 'Schmid', 'Basel', 'clara.schmid@newmail.com', 'ACTIVE', '2024-01-15'), (4, 'David', 'Fuchs', 'Zurich', 'david.fuchs@example.com', 'ACTIVE', '2024-01-15'), (5, 'Eva', 'Brunner', 'Lucerne', 'eva.brunner@example.com', 'ACTIVE', '2024-01-15'), (6, 'Frank', 'Weber', 'Zurich', 'frank.weber@example.com', 'ACTIVE', '2024-01-15'), (7, 'Grace', 'Huber', 'Bern', 'grace.huber@example.com', 'ACTIVE', '2024-01-15'), (8, 'Henry', 'Meier', 'Zurich', 'henry.meier@newmail.com', 'ACTIVE', '2024-01-15'), (9, 'Irene', 'Kunz', 'Bern', 'irene.kunz@example.com', 'ACTIVE', '2024-01-15'), (10, 'Jonas', 'Baum', 'StGallen', 'jonas.baum@example.com', 'ACTIVE', '2024-01-15'), (11, 'Kevin', 'Loosli', 'Bern', 'kevin.loosli@example.com', 'ACTIVE', '2024-01-15'), (12, 'Laura', 'Graf', 'Basel', 'laura.graf@example.com', 'ACTIVE', '2024-01-15')]\n"
     ]
    }
   ],
   "source": [
    "batch_4_chg = [\n",
    "    (2, \"Bob\",   \"Keller\", \"Zurich\", \"bob.keller@corp.com\", \"ACTIVE\"),\n",
    "    (7, \"Grace\", \"Huber\",  \"Bern\",   \"grace.huber@example.com\", \"ACTIVE\"),\n",
    "    (8, \"Henry\", \"Meier\",  \"Zurich\", \"henry.meier@newmail.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_4_load_date = \"2024-01-15\"\n",
    "batch_4 = create_full_set(batch_3, batch_4_chg, batch_4_load_date)\n",
    "print(batch_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad45e442-1453-43af-b723-f9a41f04568f",
   "metadata": {},
   "source": [
    "##### Batch 5 – Moves (2024-01-20)\n",
    " * David moves to Bern\n",
    " * Irene moves to Zurich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e98e1a-66c7-42fc-8e0b-4492cb70802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_5_chg = [\n",
    "    (4, \"David\", \"Fuchs\", \"Bern\",   \"david.fuchs@example.com\", \"ACTIVE\"),\n",
    "    (9, \"Irene\", \"Kunz\",  \"Zurich\", \"irene.kunz@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_5_load_date = \"2024-01-20\"\n",
    "batch_5 = create_full_set(batch_4, batch_5_chg, batch_5_load_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733afe4a-a276-461d-bda9-3c52fc21dc47",
   "metadata": {},
   "source": [
    "#### Batch 6 – Move back (2024-01-25)\n",
    " * David moves back to Zurich\n",
    " * Irene moves back to Bern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dbd47ad-dee3-4e7e-83ff-a7747367dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_6_chg = [\n",
    "    (4, \"David\", \"Fuchs\", \"Zurich\", \"david.fuchs@example.com\", \"ACTIVE\"),\n",
    "    (9, \"Irene\", \"Kunz\",  \"Bern\",   \"irene.kunz@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_6_load_date = \"2024-01-25\"\n",
    "batch_6 = create_full_set(batch_5, batch_6_chg, batch_6_load_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba5d2f2-99fa-4f56-b0a6-a2b00dae0842",
   "metadata": {},
   "source": [
    "#### Batch 7 – Corrections & casing (2024-02-01)\n",
    " * Jonas Correction\n",
    " * Kevin eamil change\n",
    " * laura frist_name change to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af811287-7653-4adb-b492-c9ae54fe349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_7_chg = [\n",
    "    (10, \"Jonas\", \"Bäum\",  \"StGallen\", \"jonas.baum@example.com\", \"ACTIVE\"),\n",
    "    (11, \"Kevin\", \"Loosli\",\"Bern\",     \"kevin.loosli@company.com\", \"ACTIVE\"),\n",
    "    (12, \"laura\", \"Graf\",  \"Basel\",    \"laura.graf@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_7_load_date = \"2024-02-01\"\n",
    "batch_7 = create_full_set(batch_6, batch_7_chg, batch_7_load_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a1222-1c73-4fd9-932b-0c7401781030",
   "metadata": {},
   "source": [
    "#### Batch 8 – Disappearance from source (2024-02-10)\n",
    " * Grace deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5203c418-bc32-4e83-a161-69f7e670d2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Alice', 'Meyer', 'Bern', 'alice.meyer@example.com', 'ACTIVE', '2024-02-10'), (2, 'Bob', 'Keller', 'Zurich', 'bob.keller@corp.com', 'ACTIVE', '2024-02-10'), (3, 'Clara', 'Schmid', 'Basel', 'clara.schmid@newmail.com', 'ACTIVE', '2024-02-10'), (4, 'David', 'Fuchs', 'Zurich', 'david.fuchs@example.com', 'ACTIVE', '2024-02-10'), (5, 'Eva', 'Brunner', 'Lucerne', 'eva.brunner@example.com', 'ACTIVE', '2024-02-10'), (6, 'Frank', 'Weber', 'Zurich', 'frank.weber@example.com', 'ACTIVE', '2024-02-10'), (8, 'Henry', 'Meier', 'Zurich', 'henry.meier@newmail.com', 'ACTIVE', '2024-02-10'), (9, 'Irene', 'Kunz', 'Bern', 'irene.kunz@example.com', 'ACTIVE', '2024-02-10'), (10, 'Jonas', 'Bäum', 'StGallen', 'jonas.baum@example.com', 'ACTIVE', '2024-02-10'), (11, 'Kevin', 'Loosli', 'Bern', 'kevin.loosli@company.com', 'ACTIVE', '2024-02-10'), (12, 'laura', 'Graf', 'Basel', 'laura.graf@example.com', 'ACTIVE', '2024-02-10')]\n"
     ]
    }
   ],
   "source": [
    "batch_8_chg = [\n",
    "    (7,  \"DEL\",  \"Huber\",   \"Bern\", \"grace.huber@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_8_load_date = \"2024-02-10\"\n",
    "batch_8 = create_full_set(batch_7, batch_8_chg, batch_8_load_date)\n",
    "print (batch_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7363d8e0-2010-4a9a-9004-cf313010e618",
   "metadata": {},
   "source": [
    "#### Batch 9 – Reappearance + new hire (2024-02-20)\n",
    "  * rehire Grace \n",
    "  * add Markus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43df12d1-c841-43b9-8e8b-b6a340c15a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_9_chg = [\n",
    "    (7,  \"Grace\",  \"Huber\",   \"Bern\",    \"grace.huber@example.com\", \"ACTIVE\"),\n",
    "    (13, \"Markus\", \"Steiner\",\"Lucerne\", \"markus.steiner@example.com\", \"ACTIVE\"),\n",
    "]\n",
    "batch_9_load_date = \"2024-02-20\"\n",
    "batch_9 = create_full_set(batch_8, batch_9_chg, batch_9_load_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "216d0a1b-0812-46af-b638-7b3d87e1cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"person_id\", IntegerType(), False),\n",
    "    StructField(\"first_name\", StringType(), False),\n",
    "    StructField(\"last_name\", StringType(), False),\n",
    "    StructField(\"city\", StringType(), False),\n",
    "    StructField(\"email\", StringType(), False),\n",
    "    StructField(\"status\", StringType(), False),\n",
    "    StructField(\"load_date\", DateType(), False),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d17133-758c-4125-942f-475f7b3358d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType\n",
    "\n",
    "def replay(batch):\n",
    "    df = spark.createDataFrame(batch)\n",
    "    df = df.toDF(*[f.name for f in schema])\n",
    "\n",
    "    df = df.withColumn(\"load_date\", col(\"load_date\").cast(\"date\"))\n",
    "    return df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25bc8538-bb71-4c1b-909c-ea93080c3846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scd2(df):\n",
    "    df.writeTo(\"raw_person\").append()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68007aa6-6213-45f0-a1a3-640a4d67e80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in [batch_1, batch_2, batch_3, batch_4, batch_5, batch_6, batch_7, batch_8, batch_9]:\n",
    "    df = replay(batch)\n",
    "    apply_scd2(df)   # your"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6bd607b-6fb3-41c6-851b-8bed0d5b661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sql(load_date: str):\n",
    "    stmt = f\"\"\"\n",
    "    WITH changed_records AS (\n",
    "        SELECT \n",
    "            src.*,\n",
    "            CASE \n",
    "                WHEN tgt.person_id IS NULL THEN 'NEW'\n",
    "                WHEN src.load_date > tgt.source_loaded_at THEN 'CHANGED'\n",
    "                ELSE 'UNCHANGED'\n",
    "            END AS change_classification\n",
    "        FROM raw_person src\n",
    "        LEFT JOIN (\n",
    "            SELECT \n",
    "                person_id,\n",
    "                source_loaded_at,\n",
    "                effective_start_date\n",
    "            FROM dim_person \n",
    "            WHERE is_current_version = true\n",
    "        ) tgt ON src.person_id = tgt.person_id\n",
    "        WHERE src.load_date = CAST('{load_date}' as date)\n",
    "    ),\n",
    "    records_to_process AS (\n",
    "        SELECT *\n",
    "        FROM changed_records\n",
    "        WHERE change_classification IN ('NEW', 'CHANGED')\n",
    "    ),\n",
    "    prepared_source AS (\n",
    "        -- Original records for matching existing rows (updates)\n",
    "        SELECT \n",
    "            person_id AS merge_key,  -- Used for matching\n",
    "            person_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            city,\n",
    "            email,\n",
    "            load_date,\n",
    "            status,\n",
    "            'UPDATE_EXISTING' AS operation_type\n",
    "        FROM records_to_process\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        -- Duplicate records with NULL key for insertions\n",
    "        SELECT \n",
    "            NULL AS merge_key,     -- NULL prevents matching, forces insert\n",
    "            person_id,\n",
    "            first_name,\n",
    "            last_name,\n",
    "            city,\n",
    "            email,\n",
    "            load_date,\n",
    "            status,\n",
    "            'INSERT_NEW_VERSION' AS operation_type\n",
    "        FROM records_to_process\n",
    "        WHERE change_classification = 'CHANGED'  -- Only for updates, not new records\n",
    "    )\n",
    "    \n",
    "    MERGE INTO dim_person target\n",
    "    USING prepared_source source\n",
    "    ON target.person_id = source.merge_key \n",
    "       AND target.is_current_version = true\n",
    "    -- Close existing current records for updated entities\n",
    "    WHEN MATCHED \n",
    "        AND source.operation_type = 'UPDATE_EXISTING'\n",
    "        AND source.load_date > target.source_loaded_at\n",
    "    THEN UPDATE SET\n",
    "        effective_end_date = source.load_date,\n",
    "        is_current_version = false,\n",
    "        change_type = 'SUPERSEDED',\n",
    "        pipeline_processed_at = current_timestamp()\n",
    "    -- Insert new records (both new entities and new versions)\n",
    "    WHEN NOT MATCHED \n",
    "    THEN INSERT (\n",
    "        person_id,\n",
    "        first_name,\n",
    "        last_name,\n",
    "        city,\n",
    "        email,\n",
    "        effective_start_date,\n",
    "        effective_end_date,\n",
    "        is_current_version,\n",
    "        is_active,\n",
    "        source_loaded_at,\n",
    "        pipeline_processed_at,\n",
    "        change_type,\n",
    "        record_hash\n",
    "    ) VALUES (\n",
    "        source.person_id,\n",
    "        source.first_name,\n",
    "        source.last_name,\n",
    "        source.city,\n",
    "        source.email,\n",
    "        source.load_date,\n",
    "        CAST('9999-12-31 23:59:59' AS TIMESTAMP),  -- Far future date\n",
    "        true,\n",
    "        CASE WHEN source.status = 'ACTIVE' THEN true ELSE false END,\n",
    "        source.load_date,\n",
    "        current_timestamp(),\n",
    "        CASE \n",
    "            WHEN source.operation_type = 'UPDATE_EXISTING' THEN 'NEW'\n",
    "            ELSE 'NEW_VERSION'\n",
    "        END,\n",
    "        sha2(concat_ws('|', \n",
    "            cast(source.person_id as string),\n",
    "            source.first_name,\n",
    "            source.last_name,\n",
    "            source.city,\n",
    "            source.email\n",
    "        ), 256)\n",
    "    )\n",
    "    -- Handle soft deletes for records no longer in source\n",
    "    WHEN NOT MATCHED BY SOURCE \n",
    "        AND target.is_current_version = true \n",
    "        AND target.is_active = true\n",
    "    THEN UPDATE SET\n",
    "        is_active = false,\n",
    "        change_type = 'DELETED',\n",
    "        pipeline_processed_at = current_timestamp();\n",
    "    \"\"\"\n",
    "    return stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca760dd5-046e-4e89-9d9b-4bd3cc119fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WITH changed_records AS (\n",
      "        SELECT \n",
      "            src.*,\n",
      "            CASE \n",
      "                WHEN tgt.person_id IS NULL THEN 'NEW'\n",
      "                WHEN src.load_date > tgt.source_loaded_at THEN 'CHANGED'\n",
      "                ELSE 'UNCHANGED'\n",
      "            END AS change_classification\n",
      "        FROM raw_person src\n",
      "        LEFT JOIN (\n",
      "            SELECT \n",
      "                person_id,\n",
      "                source_loaded_at,\n",
      "                effective_start_date\n",
      "            FROM dim_person \n",
      "            WHERE is_current_version = true\n",
      "        ) tgt ON src.person_id = tgt.person_id\n",
      "        WHERE src.load_date = CAST('2024-01-01' as date)\n",
      "    ),\n",
      "    records_to_process AS (\n",
      "        SELECT *\n",
      "        FROM changed_records\n",
      "        WHERE change_classification IN ('NEW', 'CHANGED')\n",
      "    ),\n",
      "    prepared_source AS (\n",
      "        -- Original records for matching existing rows (updates)\n",
      "        SELECT \n",
      "            person_id AS merge_key,  -- Used for matching\n",
      "            person_id,\n",
      "            first_name,\n",
      "            last_name,\n",
      "            city,\n",
      "            email,\n",
      "            load_date,\n",
      "            status,\n",
      "            'UPDATE_EXISTING' AS operation_type\n",
      "        FROM records_to_process\n",
      "\n",
      "        UNION ALL\n",
      "\n",
      "        -- Duplicate records with NULL key for insertions\n",
      "        SELECT \n",
      "            NULL AS merge_key,     -- NULL prevents matching, forces insert\n",
      "            person_id,\n",
      "            first_name,\n",
      "            last_name,\n",
      "            city,\n",
      "            email,\n",
      "            load_date,\n",
      "            status,\n",
      "            'INSERT_NEW_VERSION' AS operation_type\n",
      "        FROM records_to_process\n",
      "        WHERE change_classification = 'CHANGED'  -- Only for updates, not new records\n",
      "    )\n",
      "\n",
      "    MERGE INTO dim_person target\n",
      "    USING prepared_source source\n",
      "    ON target.person_id = source.merge_key \n",
      "       AND target.is_current_version = true\n",
      "    -- Close existing current records for updated entities\n",
      "    WHEN MATCHED \n",
      "        AND source.operation_type = 'UPDATE_EXISTING'\n",
      "        AND source.load_date > target.source_loaded_at\n",
      "    THEN UPDATE SET\n",
      "        effective_end_date = source.load_date,\n",
      "        is_current_version = false,\n",
      "        change_type = 'SUPERSEDED',\n",
      "        pipeline_processed_at = current_timestamp()\n",
      "    -- Insert new records (both new entities and new versions)\n",
      "    WHEN NOT MATCHED \n",
      "    THEN INSERT (\n",
      "        person_id,\n",
      "        first_name,\n",
      "        last_name,\n",
      "        city,\n",
      "        email,\n",
      "        effective_start_date,\n",
      "        effective_end_date,\n",
      "        is_current_version,\n",
      "        is_active,\n",
      "        source_loaded_at,\n",
      "        pipeline_processed_at,\n",
      "        change_type,\n",
      "        record_hash\n",
      "    ) VALUES (\n",
      "        source.person_id,\n",
      "        source.first_name,\n",
      "        source.last_name,\n",
      "        source.city,\n",
      "        source.email,\n",
      "        source.load_date,\n",
      "        CAST('9999-12-31 23:59:59' AS TIMESTAMP),  -- Far future date\n",
      "        true,\n",
      "        CASE WHEN source.status = 'ACTIVE' THEN true ELSE false END,\n",
      "        source.load_date,\n",
      "        current_timestamp(),\n",
      "        CASE \n",
      "            WHEN source.operation_type = 'UPDATE_EXISTING' THEN 'NEW'\n",
      "            ELSE 'NEW_VERSION'\n",
      "        END,\n",
      "        sha2(concat_ws('|', \n",
      "            cast(source.person_id as string),\n",
      "            source.first_name,\n",
      "            source.last_name,\n",
      "            source.city,\n",
      "            source.email\n",
      "        ), 256)\n",
      "    )\n",
      "    -- Handle soft deletes for records no longer in source\n",
      "    WHEN NOT MATCHED BY SOURCE \n",
      "        AND target.is_current_version = true \n",
      "        AND target.is_active = true\n",
      "    THEN UPDATE SET\n",
      "        is_active = false,\n",
      "        change_type = 'DELETED',\n",
      "        pipeline_processed_at = current_timestamp();\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stmt = format_sql(batch_1_load_date)\n",
    "print(stmt)\n",
    "spark.sql(stmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b06fc-5156-4454-a22d-b9ae0b12ffa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d58c4bd-4c46-4586-81c1-9e8ecfda6a84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.8 (ipykernel)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
